{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5bb0bf-23d5-4bed-943e-e761a523d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg#用于图像处理\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator#用于生成图像和对应的标签\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dccab39c-7ba4-4f21-89ea-685a6f89b475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhx/Downloads/validation-horse-or-human/horses\n",
      "['horse1-204.png', 'horse2-112.png', 'horse3-498.png', 'horse5-032.png', 'horse5-018.png', 'horse1-170.png', 'horse5-192.png', 'horse1-411.png', 'horse4-232.png', 'horse3-070.png']\n",
      "['valhuman04-20.png', 'valhuman03-01.png', 'valhuman04-08.png', 'valhuman03-15.png', 'valhuman01-04.png', 'valhuman01-10.png', 'valhuman01-11.png', 'valhuman01-05.png', 'valhuman03-14.png', 'valhuman03-00.png']\n"
     ]
    }
   ],
   "source": [
    "#获取数据\n",
    "#1.解压文件\n",
    "local_zip = '/Users/zhx/Downloads/validation-horse-or-human.zip'#指定文件目录\n",
    "zip_ref = zipfile.ZipFile(local_zip,'r')#用read方式打开zip文件\n",
    "zip_ref.extractall('/Users/zhx/Downloads/validation-horse-or-human')#解压到指定目录\n",
    "zip_ref.close()#关闭zip文件\n",
    "#2. 输入数据（图片）分流\n",
    "train_horse_dir = os.path.join('/Users/zhx/Downloads/validation-horse-or-human/horses')#存储数据地址\n",
    "print(train_horse_dir)\n",
    "train_human_dir = os.path.join('/Users/zhx/Downloads/validation-horse-or-human/humans')\n",
    "#3. 目标值（标签）分流\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5327c5d6-410d-4159-9ff5-ea74866a55b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training horse images: 128\n",
      "total training human images: 128\n"
     ]
    }
   ],
   "source": [
    "#打印数据总数\n",
    "print('total training horse images:',len(train_horse_names))\n",
    "print('total training human images:',len(train_human_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a23abd3-3511-4d7e-b54b-06c3d5004caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型创建\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9505f129-abe5-4d90-ab14-8f167a1b8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               40141312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 40,165,409\n",
      "Trainable params: 40,165,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b70949-aa05-4632-8f0f-f69dff693bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop#引入优化方法RMSprot 有衰减的累积平方梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b44ef2f1-b025-4205-86a8-051e84028fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])#metrics 表示评价方法 增加准确率的评价方法 binary_crossentropy：二进制交叉熵，用于二分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fe564a1-6e08-4252-baa7-45defb987621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)#对数据进行标准化\n",
    "#数据分类并打上标签\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/zhx/Downloads/validation-horse-or-human',\n",
    "    target_size=(300,300),\n",
    "    batch_size=8,\n",
    "    class_mode='binary' \n",
    ")#batch_size 表示数据的批量 就是一次处理多少张图片 class_mode:分类模型 binary表示0代表一类 1代表一类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54925f6c-b87b-4275-baee-d7aa3da7159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 9s 581ms/step - loss: 2.3118e-07 - acc: 1.0000\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 9s 565ms/step - loss: 1.4258e-06 - acc: 1.0000\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 9s 556ms/step - loss: 1.4366e-07 - acc: 1.0000\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 9s 550ms/step - loss: 1.2728e-07 - acc: 1.0000\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 9s 552ms/step - loss: 2.9803e-08 - acc: 1.0000\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 9s 550ms/step - loss: 1.9997e-08 - acc: 1.0000\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 9s 548ms/step - loss: 4.2018e-08 - acc: 1.0000\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 9s 547ms/step - loss: 4.9918e-08 - acc: 1.0000\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 9s 559ms/step - loss: 4.5721e-09 - acc: 1.0000\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 9s 554ms/step - loss: 1.0689e-09 - acc: 1.0000\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 9s 551ms/step - loss: 6.4963e-10 - acc: 1.0000\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 9s 554ms/step - loss: 5.4911e-08 - acc: 1.0000\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 8s 519ms/step - loss: 3.3524e-09 - acc: 1.0000\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 9s 549ms/step - loss: 4.7738e-11 - acc: 1.0000\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 9s 550ms/step - loss: 7.2128e-10 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=16,\n",
    "    epochs=15,\n",
    "    verbose=1)#verbose=1 表示显示下方的运算steps_per_epoch表示分多少次计算 这个数* batch_size批量应该真好等于全部的数据量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59199bdd-db6c-4c02-82ef-db7a8ccd5907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      " is a horse\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    " \n",
    "  # predicting images\n",
    "path = '/Users/zhx/Downloads/white-horse-3010129_1920.jpg'\n",
    "img = image.load_img(path, target_size=(300, 300))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images,batch_size=10)\n",
    "print(classes[0])\n",
    "if classes[0]>0.5:\n",
    "    print(\" is a human\")\n",
    "else:\n",
    "    print(\" is a horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6de904-2220-4b7b-9bc4-f7f875414e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
